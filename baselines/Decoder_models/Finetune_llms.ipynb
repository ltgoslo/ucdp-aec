{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cca615-498a-492f-834b-715d09a2c26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "max_seq_length = 2048 \n",
    "dtype =  torch.float16 \n",
    "load_in_4bit = False\n",
    "r_val = 128\n",
    "model_name =\"unsloth/Llama-3.2-3B-Instruct\"\n",
    "model_save = \"Llama-3.2-3B-Instruct\"\n",
    "prompt = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62b5526-6278-4e48-9c11-dc3fff15d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = model_name,\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = False,\n",
    "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e07b7f91-4c90-4ac3-9391-653b579519a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = FastLanguageModel.for_training(model)\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = r_val, \n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = r_val,\n",
    "    lora_dropout = 0, \n",
    "    bias = \"none\",\n",
    "    use_gradient_checkpointing = \"unsloth\",\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,\n",
    "    loftq_config = None,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bd42ff4-2562-4451-9304-60314cd07b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "alpaca_prompt = \"\"\"\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"instruction\"]\n",
    "    inputs       = examples[\"input\"]\n",
    "    outputs      = examples[\"output\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df8193a-d871-4c37-ae2a-fbf4a313508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "#dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
    "dataset = load_dataset(\"json\", data_files=\"/cluster/work/users/anonymous/new_jsons_prompt/train_data_json_prompt\"+str(prompt)+\".json\")\n",
    "dataset = dataset[\"train\"].map(formatting_prompts_func, batched = True,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fc700c-5c02-4eaf-b131-59250fbdc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 8,\n",
    "        warmup_steps = 10,\n",
    "        # num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 900,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = True, #not is_bfloat16_supported(),\n",
    "        bf16 = False, #is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"/cluster/work/users/anonymous/finetuneEE_US4B\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f736a4-a397-40e3-8222-18e25b5f4b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")\n",
    "\n",
    "\n",
    "trainer_stats = trainer.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e4e452-1541-47a9-a9e5-98f10de79e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Extract the information in JSONL format for the following source_text:\", # instruction\n",
    "        \"DEN - Separate bomb attacks by Al-Qaeda suspects on Saturday killed a senior army officer and three soldiers across Yemen\\'s restive south and southeast, military officials said. A bomb planted by Al-Qaeda on a road linking the towns of Seiyun and Shibam (in the southeastern province of Hadramawt) exploded when an army vehicle passed, killing three soldiers and wounding six others, a military official told AFP.The official added that two suspected Al-Qaeda members were arrested at a checkpoint at the entrance to Seiyun just hours before the attack. Hadramawt has been the scene of frequent attacks on the army.On August 17, six Al-Qaeda suspects and three soldiers were killed in clashes in the restive province where the army has boosted its deployment. In the main southern city of Aden, meanwhile, a senior Yemeni army officer was killed on Saturday when a bomb planted in his vehicle exploded, another military official said, also blaming Al-Qaeda. A bomb exploded in the car of General Ahmed Mohammed Saleh al-Omari, logistics and supplies officer of the third military region... wounding him and his son in Aden\\'s Al-Mansura district, the source said.Both were hospitalised but Omari later died of his wounds, the official and a medical source said. Yemeni authorities blame Al-Qaeda in the Arabian Peninsula, which has been branded by Washington as the extremist network\\'s deadliest franchise, for most attacks on members of the security forces.In late April, the army launched a ground offensive against AQAP in Shabwa and nearby Abyan provinces, both in the south.The group is active across several parts of Yemen, having exploited the collapse of central authority during a 2011 uprising that ousted veteran president Ali Abdullah Saleh.\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 200, use_cache = True)\n",
    "outtext = tokenizer.batch_decode(outputs)\n",
    "\n",
    "print(outtext)\n",
    "\n",
    "model.save_pretrained(\"NProStrt_\"+str(prompt)+\"_\"+model_save+str(r_val)) # Local saving\n",
    "tokenizer.save_pretrained(\"NProStrt_\"+str(prompt)+\"_\"+model_save+str(r_val))\n",
    "model.save_pretrained_merged(\"NProStrt_\"+str(prompt)+\"_\"+\"Merged_\"+model_save+str(r_val), tokenizer, save_method = \"merged_16bit\",)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
